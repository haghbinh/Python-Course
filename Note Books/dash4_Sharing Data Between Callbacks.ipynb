{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharing Data Between Callbacks\n",
    "One of the core Dash principles explained in the Getting Started Guide on Callbacks is that **Dash Callbacks must never modify variables outside of their scope**. It is not safe to modify any global variables. This chapter explains why and provides some alternative patterns for sharing state between callbacks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Share State?\n",
    "In some apps, you may have multiple callbacks that depend on expensive data processing tasks like making SQL queries, running simulations, or downloading data.\n",
    "\n",
    "Rather than have each callback run the same expensive task, you can have one callback run the task and then share the results to the rest of the callbacks.\n",
    "\n",
    "This need has been somewhat ameliorated now that you can have multiple outputs for one callback. This way, that expensive task can be done once and immediately used in all the outputs. But in some cases this still isn't ideal, for example if there are simple follow-on tasks that modify the results, like unit conversions. We shouldn't need to repeat a large database query just to change the results from Fahrenheit to Celsius!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why global variables will break your app\n",
    "Dash is designed to work in multi-user environments where multiple people may view the application at the same time and will have independent sessions.\n",
    "\n",
    "If your app uses modified `global` variables, then one user's session could set the variable to one value which would affect the next user's session.\n",
    "\n",
    "Dash is also designed to be able to run with multiple python workers so that callbacks can be executed in parallel. This is commonly done with `gunicorn` using syntax like\n",
    "\n",
    ">   gunicorn --workers 4 app:server\n",
    "\n",
    "(app refers to a file named app.py and server refers to a variable in that file named `server: server = app.server`).\n",
    "\n",
    "When Dash apps run across multiple workers, their memory is not shared. This means that if you modify a global variable in one callback, that modification will not be applied to the rest of the workers.\n",
    "\n",
    " Here is a sketch of an app with a callback that modifies data out of its scope. This type of pattern **will not work reliably** for the reasons outlined above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "df = pd.DataFrame({\n",
    "    'a': [1, 2, 3],\n",
    "    'b': [4, 1, 4],\n",
    "    'c': ['x', 'y', 'z'],\n",
    "})\n",
    "app.layout = html.Div([\n",
    "    dcc.Dropdown(\n",
    "        id='dropdown',\n",
    "        options=[{'label': i, 'value': i} for i in df['c'].unique()],\n",
    "        value='a'\n",
    "    ),\n",
    "    html.Div(id='output'),\n",
    "])\n",
    "@app.callback(Output('output', 'children'),\n",
    "              [Input('dropdown', 'value')])\n",
    "def update_output_1(value):\n",
    "    # Here, `df` is an example of a variable that is\n",
    "    # \"outside the scope of this function\".\n",
    "    # *It is not safe to modify or reassign this variable\n",
    "    #  inside this callback.*\n",
    "    global df = df[df['c'] == value]  # do not do this, this is not safe!\n",
    "    return len(df)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharing Data Between Callbacks\n",
    "In order to share data safely across multiple python processes, we need to store the data somewhere that is accessible to each of the processes.\n",
    "\n",
    "There are three main places to store this data:\n",
    "\n",
    "1. In the user's browser session\n",
    "\n",
    "2. On the disk (e.g. on a file or on a new database)\n",
    "\n",
    "3. In a shared memory space like with Redis\n",
    "\n",
    "The following three examples illustrate these approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1 - Storing Data in the Browser with a Hidden Div\n",
    "To save data in user's browser's session:\n",
    "\n",
    "- Implemented by saving the data as part of Dash's front-end store through methods explained in https://community.plotly.com/t/sharing-a-dataframe-between-plots/6173\n",
    "- Data has to be converted to a string like JSON for storage and transport\n",
    "- Data that is cached in this way will only be available in the user's current session.\n",
    "- 1. If you open up a new browser, the app's callbacks will always compute the data. The data is only cached and transported between callbacks within the session.\n",
    "- 2. As such, unlike with caching, this method doesn't increase the memory footprint of the app.\n",
    "- 3. There could be a cost in network transport. If you're sharing 10MB of data between callbacks, then that data will be transported over the network between each callback.\n",
    "- 4. If the network cost is too high, then compute the aggregations upfront and transport those. Your app likely won't be displaying 10MB of data, it will just be displaying a subset or an aggregation of it.\n",
    " This example outlines how you can perform an expensive data processing step in one callback, serialize the output at JSON, and provide it as an input to the other callbacks. This example uses standard Dash callbacks and stores the JSON-ified data inside a hidden div in the app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "global_df = pd.read_csv('...')\n",
    "app.layout = html.Div([\n",
    "    dcc.Graph(id='graph'),\n",
    "    html.Table(id='table'),\n",
    "    dcc.Dropdown(id='dropdown'),\n",
    "\n",
    "    # Hidden div inside the app that stores the intermediate value\n",
    "    html.Div(id='intermediate-value', style={'display': 'none'})\n",
    "])\n",
    "\n",
    "@app.callback(Output('intermediate-value', 'children'), [Input('dropdown', 'value')])\n",
    "def clean_data(value):\n",
    "     # some expensive clean data step\n",
    "     cleaned_df = your_expensive_clean_or_compute_step(value)\n",
    "\n",
    "     # more generally, this line would be\n",
    "     # json.dumps(cleaned_df)\n",
    "     return cleaned_df.to_json(date_format='iso', orient='split')\n",
    "\n",
    "@app.callback(Output('graph', 'figure'), [Input('intermediate-value', 'children')])\n",
    "def update_graph(jsonified_cleaned_data):\n",
    "\n",
    "    # more generally, this line would be\n",
    "    # json.loads(jsonified_cleaned_data)\n",
    "    dff = pd.read_json(jsonified_cleaned_data, orient='split')\n",
    "\n",
    "    figure = create_figure(dff)\n",
    "    return figure\n",
    "\n",
    "@app.callback(Output('table', 'children'), [Input('intermediate-value', 'children')])\n",
    "def update_table(jsonified_cleaned_data):\n",
    "    dff = pd.read_json(jsonified_cleaned_data, orient='split')\n",
    "    table = create_table(dff)\n",
    "    return table\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2 - Computing Aggregations Upfront\n",
    "Sending the computed data over the network can be expensive if the data is large. In some cases, serializing this data and JSON can also be expensive.\n",
    "\n",
    "In many cases, your app will only display a subset or an aggregation of the computed or filtered data. In these cases, you could precompute your aggregations in your data processing callback and transport these aggregations to the remaining callbacks.\n",
    "\n",
    "Here's a simple example of how you might transport filtered or aggregated data to multiple callbacks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "@app.callback(\n",
    "    Output('intermediate-value', 'children'),\n",
    "    [Input('dropdown', 'value')])\n",
    "def clean_data(value):\n",
    "     # an expensive query step\n",
    "     cleaned_df = your_expensive_clean_or_compute_step(value)\n",
    "\n",
    "     # a few filter steps that compute the data\n",
    "     # as it's needed in the future callbacks\n",
    "     df_1 = cleaned_df[cleaned_df['fruit'] == 'apples']\n",
    "     df_2 = cleaned_df[cleaned_df['fruit'] == 'oranges']\n",
    "     df_3 = cleaned_df[cleaned_df['fruit'] == 'figs']\n",
    "\n",
    "     datasets = {\n",
    "         'df_1': df_1.to_json(orient='split', date_format='iso'),\n",
    "         'df_2': df_2.to_json(orient='split', date_format='iso'),\n",
    "         'df_3': df_3.to_json(orient='split', date_format='iso'),\n",
    "     }\n",
    "\n",
    "     return json.dumps(datasets)\n",
    "\n",
    "@app.callback(\n",
    "    Output('graph', 'figure'),\n",
    "    [Input('intermediate-value', 'children')])\n",
    "def update_graph_1(jsonified_cleaned_data):\n",
    "    datasets = json.loads(jsonified_cleaned_data)\n",
    "    dff = pd.read_json(datasets['df_1'], orient='split')\n",
    "    figure = create_figure_1(dff)\n",
    "    return figure\n",
    "\n",
    "@app.callback(\n",
    "    Output('graph', 'figure'),\n",
    "    [Input('intermediate-value', 'children')])\n",
    "def update_graph_2(jsonified_cleaned_data):\n",
    "    datasets = json.loads(jsonified_cleaned_data)\n",
    "    dff = pd.read_json(datasets['df_2'], orient='split')\n",
    "    figure = create_figure_2(dff)\n",
    "    return figure\n",
    "\n",
    "@app.callback(\n",
    "    Output('graph', 'figure'),\n",
    "    [Input('intermediate-value', 'children')])\n",
    "def update_graph_3(jsonified_cleaned_data):\n",
    "    datasets = json.loads(jsonified_cleaned_data)\n",
    "    dff = pd.read_json(datasets['df_3'], orient='split')\n",
    "    figure = create_figure_3(dff)\n",
    "    return figure\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3 - Caching and Signaling\n",
    "This example:\n",
    "\n",
    "- Uses Redis via Flask-Cache for storing “global variables”. This data is accessed through a function, the output of which is cached and keyed by its input arguments.\n",
    "- Uses the hidden div solution to send a signal to the other callbacks when the expensive computation is complete.\n",
    "- Note that instead of Redis, you could also save this to the file system. See https://flask-caching.readthedocs.io/en/latest/ for more details.\n",
    "- This “signaling” is cool because it allows the expensive computation to only take up one process. Without this type of signaling, each callback could end up computing the expensive computation in parallel, locking four processes instead of one.\n",
    "This approach is also advantageous in that future sessions can use the pre-computed value. This will work well for apps that have a small number of inputs.\n",
    "\n",
    "Here’s what this example looks like. Some things to note:\n",
    "\n",
    "- I’ve simulated an expensive process by using a time.sleep(5).\n",
    "- When the app loads, it takes five seconds to render all four graphs.\n",
    "- The initial computation only blocks one process.\n",
    "- Once the computation is complete, the signal is sent and four callbacks are executed in parallel to render the graphs. Each of these callbacks retrieves the data from the “global store”: the Redis or filesystem cache.\n",
    "- I’ve set processes=6 in app.run_server so that multiple callbacks can be executed in parallel. In production, this is done with something like  `gunicorn --workers 6 --threads 2 app:server`\n",
    "- Selecting a value in the dropdown will take less than five seconds if it has already been selected in the past. This is because the value is being pulled from the cache.\n",
    "- Similarly, reloading the page or opening the app in a new window is also fast because the initial state and the initial expensive computation has already been computed.\n",
    "\n",
    "Here's what this example looks like in code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dash.dependencies import Input, Output\n",
    "from flask_caching import Cache\n",
    "\n",
    "\n",
    "external_stylesheets = [\n",
    "    # Dash CSS\n",
    "    'https://codepen.io/chriddyp/pen/bWLwgP.css',\n",
    "    # Loading screen CSS\n",
    "    'https://codepen.io/chriddyp/pen/brPBPO.css']\n",
    "\n",
    "app = dash.Dash(__name__, external_stylesheets=external_stylesheets)\n",
    "CACHE_CONFIG = {\n",
    "    # try 'filesystem' if you don't want to setup redis\n",
    "    'CACHE_TYPE': 'redis',\n",
    "    'CACHE_REDIS_URL': os.environ.get('REDIS_URL', 'redis://localhost:6379')\n",
    "}\n",
    "cache = Cache()\n",
    "cache.init_app(app.server, config=CACHE_CONFIG)\n",
    "\n",
    "N = 100\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'category': (\n",
    "        (['apples'] * 5 * N) +\n",
    "        (['oranges'] * 10 * N) +\n",
    "        (['figs'] * 20 * N) +\n",
    "        (['pineapples'] * 15 * N)\n",
    "    )\n",
    "})\n",
    "df['x'] = np.random.randn(len(df['category']))\n",
    "df['y'] = np.random.randn(len(df['category']))\n",
    "\n",
    "app.layout = html.Div([\n",
    "    dcc.Dropdown(\n",
    "        id='dropdown',\n",
    "        options=[{'label': i, 'value': i} for i in df['category'].unique()],\n",
    "        value='apples'\n",
    "    ),\n",
    "    html.Div([\n",
    "        html.Div(dcc.Graph(id='graph-1'), className=\"six columns\"),\n",
    "        html.Div(dcc.Graph(id='graph-2'), className=\"six columns\"),\n",
    "    ], className=\"row\"),\n",
    "    html.Div([\n",
    "        html.Div(dcc.Graph(id='graph-3'), className=\"six columns\"),\n",
    "        html.Div(dcc.Graph(id='graph-4'), className=\"six columns\"),\n",
    "    ], className=\"row\"),\n",
    "\n",
    "    # hidden signal value\n",
    "    html.Div(id='signal', style={'display': 'none'})\n",
    "])\n",
    "\n",
    "\n",
    "# perform expensive computations in this \"global store\"\n",
    "# these computations are cached in a globally available\n",
    "# redis memory store which is available across processes\n",
    "# and for all time.\n",
    "@cache.memoize()\n",
    "def global_store(value):\n",
    "    # simulate expensive query\n",
    "    print('Computing value with {}'.format(value))\n",
    "    time.sleep(5)\n",
    "    return df[df['category'] == value]\n",
    "\n",
    "\n",
    "def generate_figure(value, figure):\n",
    "    fig = copy.deepcopy(figure)\n",
    "    filtered_dataframe = global_store(value)\n",
    "    fig['data'][0]['x'] = filtered_dataframe['x']\n",
    "    fig['data'][0]['y'] = filtered_dataframe['y']\n",
    "    fig['layout'] = {'margin': {'l': 20, 'r': 10, 'b': 20, 't': 10}}\n",
    "    return fig\n",
    "\n",
    "\n",
    "@app.callback(Output('signal', 'children'), [Input('dropdown', 'value')])\n",
    "def compute_value(value):\n",
    "    # compute value and send a signal when done\n",
    "    global_store(value)\n",
    "    return value\n",
    "\n",
    "\n",
    "@app.callback(Output('graph-1', 'figure'), [Input('signal', 'children')])\n",
    "def update_graph_1(value):\n",
    "    # generate_figure gets data from `global_store`.\n",
    "    # the data in `global_store` has already been computed\n",
    "    # by the `compute_value` callback and the result is stored\n",
    "    # in the global redis cached\n",
    "    return generate_figure(value, {\n",
    "        'data': [{\n",
    "            'type': 'scatter',\n",
    "            'mode': 'markers',\n",
    "            'marker': {\n",
    "                'opacity': 0.5,\n",
    "                'size': 14,\n",
    "                'line': {'border': 'thin darkgrey solid'}\n",
    "            }\n",
    "        }]\n",
    "    })\n",
    "\n",
    "\n",
    "@app.callback(Output('graph-2', 'figure'), [Input('signal', 'children')])\n",
    "def update_graph_2(value):\n",
    "    return generate_figure(value, {\n",
    "        'data': [{\n",
    "            'type': 'scatter',\n",
    "            'mode': 'lines',\n",
    "            'line': {'shape': 'spline', 'width': 0.5},\n",
    "        }]\n",
    "    })\n",
    "\n",
    "\n",
    "@app.callback(Output('graph-3', 'figure'), [Input('signal', 'children')])\n",
    "def update_graph_3(value):\n",
    "    return generate_figure(value, {\n",
    "        'data': [{\n",
    "            'type': 'histogram2d',\n",
    "        }]\n",
    "    })\n",
    "\n",
    "\n",
    "@app.callback(Output('graph-4', 'figure'), [Input('signal', 'children')])\n",
    "def update_graph_4(value):\n",
    "    return generate_figure(value, {\n",
    "        'data': [{\n",
    "            'type': 'histogram2dcontour',\n",
    "        }]\n",
    "    })\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True, processes=6)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4 - User-Based Session Data on the Server\n",
    "The previous example cached computations on the filesystem and those computations were accessible for all users.\n",
    "\n",
    "In some cases, you want to keep the data isolated to user sessions: one user's derived data shouldn't update the next user's derived data. One way to do this is to save the data in a hidden Div, as demonstrated in the first example.\n",
    "\n",
    "Another way to do this is to save the data on the filesystem cache with a session ID and then reference the data using that session ID. Because data is saved on the server instead of transported over the network, this method is generally faster than the \"hidden div\" method.\n",
    "\n",
    "This example was originally discussed in a Dash Community Forum thread.\n",
    "\n",
    "This example:\n",
    "\n",
    "- Caches data using the flask_caching filesystem cache. You can also save to an in-memory database like Redis.\n",
    "- Serializes the data as JSON.\n",
    "- - If you are using Pandas, consider serializing with Apache Arrow. Community thread\n",
    "- Saves session data up to the number of expected concurrent users. This prevents the cache from being overfilled with data.\n",
    "- Creates unique session IDs by embedding a hidden random string into the app's layout and serving a unique layout on every page load.\n",
    "> Note: As with all examples that send data to the client, be aware that these sessions aren't necessarily secure or encrypted. These session IDs may be vulnerable to Session Fixation style attacks.\n",
    "\n",
    "Here's what this example looks like in code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "import dash\n",
    "from dash.dependencies import Input, Output\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import datetime\n",
    "from flask_caching import Cache\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "external_stylesheets = [\n",
    "    # Dash CSS\n",
    "    'https://codepen.io/chriddyp/pen/bWLwgP.css',\n",
    "    # Loading screen CSS\n",
    "    'https://codepen.io/chriddyp/pen/brPBPO.css']\n",
    "\n",
    "app = dash.Dash(__name__, external_stylesheets=external_stylesheets)\n",
    "cache = Cache(app.server, config={\n",
    "    'CACHE_TYPE': 'redis',\n",
    "    # Note that filesystem cache doesn't work on systems with ephemeral\n",
    "    # filesystems like Heroku.\n",
    "    'CACHE_TYPE': 'filesystem',\n",
    "    'CACHE_DIR': 'cache-directory',\n",
    "\n",
    "    # should be equal to maximum number of users on the app at a single time\n",
    "    # higher numbers will store more data in the filesystem / redis cache\n",
    "    'CACHE_THRESHOLD': 200\n",
    "})\n",
    "\n",
    "\n",
    "def get_dataframe(session_id):\n",
    "    @cache.memoize()\n",
    "    def query_and_serialize_data(session_id):\n",
    "        # expensive or user/session-unique data processing step goes here\n",
    "\n",
    "        # simulate a user/session-unique data processing step by generating\n",
    "        # data that is dependent on time\n",
    "        now = datetime.datetime.now()\n",
    "\n",
    "        # simulate an expensive data processing task by sleeping\n",
    "        time.sleep(5)\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            'time': [\n",
    "                str(now - datetime.timedelta(seconds=15)),\n",
    "                str(now - datetime.timedelta(seconds=10)),\n",
    "                str(now - datetime.timedelta(seconds=5)),\n",
    "                str(now)\n",
    "            ],\n",
    "            'values': ['a', 'b', 'a', 'c']\n",
    "        })\n",
    "        return df.to_json()\n",
    "\n",
    "    return pd.read_json(query_and_serialize_data(session_id))\n",
    "\n",
    "\n",
    "def serve_layout():\n",
    "    session_id = str(uuid.uuid4())\n",
    "\n",
    "    return html.Div([\n",
    "        html.Div(session_id, id='session-id', style={'display': 'none'}),\n",
    "        html.Button('Get data', id='get-data-button'),\n",
    "        html.Div(id='output-1'),\n",
    "        html.Div(id='output-2')\n",
    "    ])\n",
    "\n",
    "\n",
    "app.layout = serve_layout\n",
    "\n",
    "\n",
    "@app.callback(Output('output-1', 'children'),\n",
    "              [Input('get-data-button', 'n_clicks'),\n",
    "               Input('session-id', 'children')])\n",
    "def display_value_1(value, session_id):\n",
    "    df = get_dataframe(session_id)\n",
    "    return html.Div([\n",
    "        'Output 1 - Button has been clicked {} times'.format(value),\n",
    "        html.Pre(df.to_csv())\n",
    "    ])\n",
    "\n",
    "\n",
    "@app.callback(Output('output-2', 'children'),\n",
    "              [Input('get-data-button', 'n_clicks'),\n",
    "               Input('session-id', 'children')])\n",
    "def display_value_2(value, session_id):\n",
    "    df = get_dataframe(session_id)\n",
    "    return html.Div([\n",
    "        'Output 2 - Button has been clicked {} times'.format(value),\n",
    "        html.Pre(df.to_csv())\n",
    "    ])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three things to notice in this example:\n",
    "\n",
    "1. The timestamps of the dataframe don't update when we retrieve the data. This data is cached as part of the user's session.\n",
    "2. Retrieving the data initially takes five seconds but successive queries are instant, as the data has been cached.\n",
    "3. The second session displays different data than the first session: the data that is shared between callbacks is isolated to individual user sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
